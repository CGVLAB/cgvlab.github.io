<!DOCTYPE html>

<html>
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="apple-touch-icon" sizes="180x180" href="/theme/images/icons/apple-touch-icon.png?v=1">
  <link rel="icon" type="image/png" sizes="32x32" href="/theme/images/icons/favicon-32x32.png?v=1">
  <link rel="icon" type="image/png" sizes="194x194" href="/theme/images/icons/favicon-194x194.png?v=1">
  <link rel="icon" type="image/png" sizes="192x192"
    href="/theme/images/icons/android-chrome-192x192.png?v=1">
  <link rel="icon" type="image/png" sizes="16x16" href="/theme/images/icons/favicon-16x16.png?v=1">
  <link rel="manifest" href="/theme/images/icons/site.webmanifest?v=1">
  <link rel="mask-icon" href="/theme/images/icons/safari-pinned-tab.svg?v=1" color="#000000">
  <link rel="shortcut icon" href="/theme/images/icons/favicon.ico?v=1">

  <meta name="msapplication-TileColor" content="#000000">
  <meta name="msapplication-TileImage" content="/theme/images/icons/mstile-144x144.png?v=1">
  <meta name="msapplication-config" content="/theme/images/icons/browserconfig.xml?v=1">
  <meta name="theme-color" content="#000000">

  <link rel="stylesheet" href="/theme/css/main.css">

  <script src="/dependencies/js/jquery/jquery-3.6.0.min.js"></script>
  <script src="/dependencies/js/bootstrap/bootstrap.bundle.min.js"></script>
  <script src="/dependencies/js/jquery/pagination.min.js"></script>

  <!-- Begin Jekyll SEO tag v2.7.1 -->
<title>Research | CGVLab</title>
<meta name="generator" content="Jekyll v4.2.0" />
<meta property="og:title" content="Research" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Computer Graphics and Visualization Laboratory at Purdue University" />
<meta property="og:description" content="Computer Graphics and Visualization Laboratory at Purdue University" />
<link rel="canonical" href="https://cgvlab.purdue.edu/research/" />
<meta property="og:url" content="https://cgvlab.purdue.edu/research/" />
<meta property="og:site_name" content="CGVLab" />
<meta property="og:image" content="https://cgvlab.purdue.edu/theme/images/icon.png" />
<meta name="twitter:card" content="summary_large_image" />
<meta property="twitter:image" content="https://cgvlab.purdue.edu/theme/images/icon.png" />
<meta property="twitter:title" content="Research" />
<script type="application/ld+json">
{"description":"Computer Graphics and Visualization Laboratory at Purdue University","@type":"WebPage","url":"https://cgvlab.purdue.edu/research/","publisher":{"@type":"Organization","logo":{"@type":"ImageObject","url":"https://cgvlab.purdue.edu/theme/images/icon.png"}},"headline":"Research","image":"https://cgvlab.purdue.edu/theme/images/icon.png","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->


    <!-- Google Analytics -->
    <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-82472331-1', 'auto');
	ga('send', 'pageview', { 'page': location.pathname + location.search + location.hash});
	ga('set', 'anonymizeIp', false);
    </script>
    <!-- End Google Analytics -->
    </head>

<body class="bg-light text-dark">
  <div class="container-fluid bg-dark border-bottom border-primary lab-border">
	<div class="container">
		<nav class="navbar navbar-expand-lg navbar-dark">
			<a class="navbar-brand p-1" href="https://www.purdue.edu">
				<img src="/theme/images/purdue_logo_dark_bg.svg" width="512" class="img-fluid" alt="Purdue University logo">
			</a>
			
			<div class="d-inline-flex flex-column lab-header mr-2">
				<a href="/"><h2 class="text-light m-0 pt-1 pb-1 pl-3">CGVLab</h2></a>
			</div>

			<button class="navbar-toggler m-2" type="button" data-toggle="collapse" data-target="#navbarSupportedContent"
				aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
				<span class="navbar-toggler-icon"></span>
			</button>
		
			<div id="navbarSupportedContent" class="collapse navbar-collapse">
				<ul class="navbar-nav">
					
					<li class="nav-item mx-3">
						
						<a class="h5 nav-link lab-nav-link m-0 " href="/">Home</a>
					</li>
					
					<li class="nav-item mx-3">
						
						<a class="h5 nav-link lab-nav-link m-0 " href="/news/">News</a>
					</li>
					
					<li class="nav-item mx-3">
						
						<a class="h5 nav-link lab-nav-link m-0 active" href="/research/">Research</a>
					</li>
					
					<li class="nav-item mx-3">
						
						<a class="h5 nav-link lab-nav-link m-0 active" href="/publications/">Publications</a>
					</li>
					
					<li class="nav-item mx-3">
						
						<a class="h5 nav-link lab-nav-link m-0 active" href="/team/">Team</a>
					</li>
					
					<li class="nav-item mx-3">
						
						<a class="h5 nav-link lab-nav-link m-0 active" href="/classes/">Classes</a>
					</li>
					
				</ul>
			</div>
		</nav>
	</div>
</div>

  <div id="lab-main" class="container bg-light text-dark mx-auto my-3">
    <div class="row">
    <div class="col">
        <h1>Research</h1>
<hr />

<h3>List of topics</h3>
<ul>
    
    <li><a href="#superimages">Superimages: Image Generalization through Camera Model Design</a></li>
    
    <li><a href="#procedural_modeling">Procedural & Inverse Procedural Modeling</a></li>
    
    <li><a href="#urban_modeling_simulation">Urban Modeling and Simulation</a></li>
    
    <li><a href="#augmented_reality_surgery">Augmented Reality Surgical Telementoring</a></li>
    
    <li><a href="#simulation_natural_phenomena">Simulation of Natural Phenomena</a></li>
    
    <li><a href="#computational_archeology">Computational Archaeological</a></li>
    
    <li><a href="#animation_instructor">Computer Animation Instructor Avatars for Research on Non-Verbal Communication in Education</a></li>
    
    <li><a href="#neural_rendering">Neural Rendering</a></li>
    
    <li><a href="#image_based_vision_correction">Image Based Vision Correction</a></li>
    
</ul>

<hr />

<div class="container">
    
    <h2 id="superimages">Superimages: Image Generalization through Camera Model Design</h2>
    <div class="row mb-4">
        
        <div class="col-md-3">
            <img src="/resources/images/research/super_image_teapot.jpg" alt="Image for project Superimages: Image Generalization through Camera Model Design" class="img-fluid img-thumbnail rounded mb-2" />
        </div>
        <div class="col-md-9">
            <p>We propose an image generalization that removes the uniform sampling rate and single viewpoint constraints of conventional images to increase their information bandwidth. The image generalization is implemented through camera model design, a novel computer graphics paradigm that replaces the conventional linear rays with curved rays, which are routed to sample a 3D dataset comprehensively, continuously, and non-redundantly. The image generalization has benefits in a variety of contexts, including in parallel, focus+context, and remote visualization; in virtual, augmented, and diminished reality; and in the acceleration of higher-order rendering effects.</p>
        </div>
        
    </div>
    
    <h2 id="procedural_modeling">Procedural & Inverse Procedural Modeling</h2>
    <div class="row mb-4">
        
        <div class="col-md-3">
            <img src="/resources/images/research/procedural_modeling.jpg" alt="Image for project Procedural & Inverse Procedural Modeling" class="img-fluid img-thumbnail rounded mb-2" />
        </div>
        <div class="col-md-9">
            <p>A procedural model is a model represented by a code - for example, C++, Python, L-system, or a shape grammar. The objective of inverse procedural modeling is to find a code that would represent a given structure. We have presented several results in the generation of inverse procedural models for regular structures that are represented as L-systems, split grammars or shape grammars. For example, 3D models of biological trees were encoded as parameters of a simulation system that generates them. Buildings and large subsets of cities have been successfully subjected to inverse procedural modeling. Also, inverse procedural models have been learned from existing structures in artistic design, such as interactive "brushing" of virtual worlds.</p>
        </div>
        
    </div>
    
    <h2 id="urban_modeling_simulation">Urban Modeling and Simulation</h2>
    <div class="row mb-4">
        
        <div class="col-md-3">
            <img src="/resources/images/research/urban_modeling.jpg" alt="Image for project Urban Modeling and Simulation" class="img-fluid img-thumbnail rounded mb-2" />
        </div>
        <div class="col-md-9">
            <p>Our objective is to capture, simulate, and modify models of urban environments. Today, more than half of the world's population of 7 billion people lives in cities - and that number is only expected to grow over the next 30 years. Cities, and urban spaces of all sizes, are however extremely complex and their modeling is still not solved. We pursue multi-disciplinary research focused on visual computing and artificial intelligence (AI) tools for improving the complex urban ecosystem and for "what-if" exploration of sustainable urban designs, including integrating urban 3D modeling, simulation, meteorology, vegetation, and traffic modeling. To date, we have developed several algorithms and large-scale software systems using ground-level imagery, aerial imagery, satellite imagery, GIS data, and forward and inverse procedural modeling to create/modify 3D and 2D urban models, and we have deployed cyberinfrastructure prototypes.</p>
        </div>
        
    </div>
    
    <h2 id="augmented_reality_surgery">Augmented Reality Surgical Telementoring</h2>
    <div class="row mb-4">
        
        <div class="col-md-3">
            <img src="/resources/images/research/surgical_telementoring.jpg" alt="Image for project Augmented Reality Surgical Telementoring" class="img-fluid img-thumbnail rounded mb-2" />
        </div>
        <div class="col-md-9">
            <p>Current surgical telementoring systems require a trainee surgeon to shift focus frequently between the operating field and a nearby monitor that shows a video fo the operating field annotated by a remote mentor. These focus shifts can lead to surgical care delays and errors. We propose a novel approach to surgical telementoring that avoids focus shifts using an augmented reality (AR) interface that integrates the annotations directly into the trainee's view of the surgical field.</p>
        </div>
        
    </div>
    
    <h2 id="simulation_natural_phenomena">Simulation of Natural Phenomena</h2>
    <div class="row mb-4">
        
        <div class="col-md-3">
            <img src="/resources/images/research/simulation_nature.jpg" alt="Image for project Simulation of Natural Phenomena" class="img-fluid img-thumbnail rounded mb-2" />
        </div>
        <div class="col-md-9">
            <p>One of the long open problems in Computer Graphics is the visual simulation of Nature. Although the output of those simulations is 3D geometric models, an in-depth understanding of the underlying processes is usually necessary. We have a long history of simulating virtual erosion that generates visually plausible terrains. We have developed several models for river generations and terrain modeling in general. Another exciting area is a simulation of vegetation. Trees and plants are complex systems with a shape defined by competition for resources, among which light is the most important one. By incorporating competition for light into the tree developmental process (growth), we can simulate very complex tree shapes as well as ecosystems of trees competing for resources. We have also presented models of trees growing under the influence of wind.</p>
        </div>
        
    </div>
    
    <h2 id="computational_archeology">Computational Archaeological</h2>
    <div class="row mb-4">
        
        <div class="col-md-3">
            <img src="/resources/images/research/computational_archaeology.jpg" alt="Image for project Computational Archaeological" class="img-fluid img-thumbnail rounded mb-2" />
        </div>
        <div class="col-md-9">
            <p>Modeling and understanding the evolution of urbanization over the course of human history constitutes a key aspect of human civilization, and helps stakeholders make better informed decisions for future urban development. In this project, and together with several teams of archaeologists from Europe and the Americas, we provide solutions towards enabling a deep generative modeling process from sparse but structured (historical urban) data. Such sites exhibit anthropogenic features such as right angles, straight edges, parallelism, and symmetries which we exploit with visual computing and deep-learning driven segmentation, classification, and completion, to ultimately recreate the past from the few remnants remaining.</p>
        </div>
        
    </div>
    
    <h2 id="animation_instructor">Computer Animation Instructor Avatars for Research on Non-Verbal Communication in Education</h2>
    <div class="row mb-4">
        
        <div class="col-md-3">
            <img src="/resources/images/research/instructor_avatar.jpg" alt="Image for project Computer Animation Instructor Avatars for Research on Non-Verbal Communication in Education" class="img-fluid img-thumbnail rounded mb-2" />
        </div>
        <div class="col-md-9">
            <p>Almost a century ago, Edward Sapir noted that we “respond to gestures with an extreme alertness” according to “an elaborate and secret code that is written nowhere, known to none, and understood by all”. Together with psychology researchers we work to break the code of effective instructor gestures in education. We are developing a system of computer animation instructor avatars to research instructor gesture effectiveness in the context of mathematics learning. We examine both gestures that help convey the mathematical concepts as well as gestures that might convey an appealing and engaging instructor personality.</p>
        </div>
        
    </div>
    
    <h2 id="neural_rendering">Neural Rendering</h2>
    <div class="row mb-4">
        
        <div class="col-md-3">
            <img src="/resources/images/research/soft_shadow_networks.jpg" alt="Image for project Neural Rendering" class="img-fluid img-thumbnail rounded mb-2" />
        </div>
        <div class="col-md-9">
            <p>We explored data-driven methods for novel neural rendering given only 2D information as inputs. Our neural rendering algorithms render realistic 3D effects for 2D image composition, including soft shadows and reflections. An efficient data generation process is proposed to satisfy the deep neural networks. A new 2.5D data representation called height map is proposed to enable hard shadow rendering in our proposed novel space. A controllable soft shadow rendering algorithm is further proposed based on our pipeline. Our method has a huge potential to satisfy artists' and designers' needs.</p>
        </div>
        
    </div>
    
    <h2 id="image_based_vision_correction">Image Based Vision Correction</h2>
    <div class="row mb-4">
        
        <div class="col-md-3">
            <img src="/resources/images/research/image-based_vision_correction.jpg" alt="Image for project Image Based Vision Correction" class="img-fluid img-thumbnail rounded mb-2" />
        </div>
        <div class="col-md-9">
            <p>Vision plays a central and critical role in our lives. Significant research and technology has been devoted to producing high-quality printed material, to creating compelling digital displays of high resolution and of large color gamut and dynamic range, and to generating and rendering realistic visual imagery. Nonetheless blur is a natural phenomenon that occurs due to human vision aberrations (e.g., presbyopia, myopia) and due to physical phenomena (e.g., motion). In this project, we pursue preemptive image-based solutions to generate computer-displayed imagery that is resistant to the above blur phenomenon, yielding crisper imagery.</p>
        </div>
        
    </div>
    
</div>

    </div>
</div>
  </div>
  <div class="container-fluid px-3 py-3 mt-auto bg-dark text-light border-top border-primary lab-border lab-link-light">
	<div class="footer container">
		<div class="row justify-content-center">
			<div class="col-sm-8">
				<h5>CGVLab Website</h5>
				<p>
					We are part of the <a href="https://www.cs.purdue.edu/">Department of Computer Science</a> at <a href="https://www.purdue.edu/">Purdue University</a>.
				</p>
				<p>
					(<a href="http://wiki.cs.purdue.edu/cgvlab/doku.php">Internal Lab Wiki</a>)
				</p>
				<p>
					Copyright &copy; 2022 CGVLab. Site made with <a href="https://jekyllrb.com">Jekyll</a>.
				</p>
			</div>
			<div class="col-sm-4 mt-3 mt-sm-0">
				<h5>Address</h5>
				<p>
					Lawson Computer Science Building (LWSN) Room 3151, Purdue University
					<br>
					305 N. University Street, West Lafayette,
					IN 47907
					<br>
					(<a href="https://goo.gl/maps/kWo74ytXx42Mv5TD8" target="_blank">Map</a>)
				</p>
				
			</div>
		</div>
	</div>
</div>
</body>

</html>